# LLM_research

### General frameworks
Paper | Short description | Links  |  Release      
-- | -- | -- | --  
[OLMo - Accelerating the science of Language Models](https://arxiv.org/pdf/2402.00838v2.pdf) | First release of a truly open language model with access to data, training code, models and evaluation code | [Model weights](https://huggingface.co/allenai/OLMo-7B) <br> [Code](https://github.com/allenai/OLMo) <br> [Data](https://huggingface.co/datasets/allenai/dolma) <br> [Evaluation](https://github.com/allenai/OLMo-Eval) <br> [Instruction tuning](https://github.com/allenai/open-instruct) | Feb'24  

### Foundation
Paper | Short description | Github / Other links  |  Release      
-- | -- | -- | --  
[Retentive Network: A Successor to Transformer for Large Language Models](https://arxiv.org/pdf/2307.08621v4.pdf) | Alternative foundation architecture for training parallelism and low-cost inference | [Github](https://github.com/microsoft/unilm/tree/master/retnet) | Jul'23  
### Pre-training  
Paper | Short description | Github / Other links  
-- | -- | --  
### Fine tuning  
Paper | Short description | Github / Other links  
-- | -- | --  
### Datasets  
Paper | Short description | Github / Other links  
-- | -- | --  
